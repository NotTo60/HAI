name: Provision Infra and Run Tests

on:
  push:
    branches: [main]

jobs:
  provision:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Ensure SSH key exists for Terraform
        run: |
          if [ ! -f terraform/id_rsa.pub ]; then
            ssh-keygen -t rsa -b 2048 -f terraform/id_rsa -N ""
          fi

      - name: Generate new SSH key for ec2-user
        run: |
          # Generate a new SSH key pair specifically for ec2-user
          ssh-keygen -t rsa -b 2048 -f terraform/ec2_user_rsa -N ""
          echo "Generated new SSH key pair for ec2-user"
          echo "Public key:"
          cat terraform/ec2_user_rsa.pub

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: "1.5.0"

      - name: Verify Terraform Installation
        run: |
          echo "=== TERRAFORM INSTALLATION VERIFICATION ==="
          echo "Terraform version:"
          terraform version
          echo "Terraform location:"
          which terraform
          echo "PATH:"
          echo $PATH
          echo "=== END VERIFICATION ==="

      - name: Validate AWS Credentials
        run: |
          echo "Validating AWS credentials..."
          aws sts get-caller-identity
          echo "AWS credentials are valid!"
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_DEFAULT_REGION: us-east-1

      - name: Remove existing AWS key pair if present
        run: |
          aws ec2 delete-key-pair --key-name hai-ci-ec2-user-key || true
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_DEFAULT_REGION: us-east-1

      - name: Clean up conflicting subnets
        run: |
          echo "Checking for existing subnets that might conflict..."
          # Get VPC ID
          VPC_ID=$(aws ec2 describe-vpcs --query 'Vpcs[0].VpcId' --output text 2>/dev/null || echo "")
          if [ ! -z "$VPC_ID" ]; then
            echo "Found VPC: $VPC_ID"
            # List subnets in the VPC that might conflict with our new CIDR
            SUBNETS=$(aws ec2 describe-subnets --filters "Name=vpc-id,Values=$VPC_ID" --query 'Subnets[?CidrBlock==`10.0.200.0/24`].SubnetId' --output text 2>/dev/null || echo "")
            if [ ! -z "$SUBNETS" ]; then
              echo "Found conflicting subnet(s): $SUBNETS"
              echo "Deleting conflicting subnets..."
              for SUBNET in $SUBNETS; do
                aws ec2 delete-subnet --subnet-id $SUBNET || echo "Failed to delete subnet $SUBNET"
              done
            else
              echo "No conflicting subnets found with CIDR 10.0.200.0/24"
            fi
            
            # Also check for any subnets in the 10.0.x.x range that might overlap
            echo "Checking for any subnets in 10.0.x.x range..."
            ALL_SUBNETS=$(aws ec2 describe-subnets --filters "Name=vpc-id,Values=$VPC_ID" --query 'Subnets[?starts_with(CidrBlock, `10.0.`)].{SubnetId:SubnetId,CidrBlock:CidrBlock}' --output json 2>/dev/null || echo "[]")
            echo "Existing subnets in 10.0.x.x range: $ALL_SUBNETS"
            
            # If there are any subnets in the 10.0.x.x range, delete them all to avoid conflicts
            SUBNET_IDS=$(aws ec2 describe-subnets --filters "Name=vpc-id,Values=$VPC_ID" --query 'Subnets[?starts_with(CidrBlock, `10.0.`)].SubnetId' --output text 2>/dev/null || echo "")
            if [ ! -z "$SUBNET_IDS" ]; then
              echo "Found existing subnets in 10.0.x.x range, deleting all to avoid conflicts: $SUBNET_IDS"
              for SUBNET_ID in $SUBNET_IDS; do
                echo "Deleting subnet: $SUBNET_ID"
                aws ec2 delete-subnet --subnet-id $SUBNET_ID || echo "Failed to delete subnet $SUBNET_ID"
              done
            fi
          else
            echo "No VPC found"
          fi
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_DEFAULT_REGION: us-east-1

      - name: Terraform Init and Apply
        run: |
          echo "=== TERRAFORM EXECUTION DEBUG ==="
          echo "Current directory: $(pwd)"
          echo "Terraform directory contents:"
          ls -la terraform/
          echo "Terraform executable:"
          which terraform
          echo "Terraform version:"
          terraform version
          echo "=== STARTING TERRAFORM ==="
          cd terraform
          echo "Changed to terraform directory: $(pwd)"
          terraform init
          terraform apply -auto-approve
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}

      - name: Output VM IPs
        id: tf_outputs
        run: |
          echo "=== TERRAFORM OUTPUT DEBUG ==="
          echo "Current directory: $(pwd)"
          echo "Terraform executable:"
          which terraform
          echo "Terraform version:"
          terraform version
          echo "=== GETTING TERRAFORM OUTPUTS ==="
          cd terraform
          echo "Changed to terraform directory: $(pwd)"
          echo "linux_ip=$(terraform output -raw linux_ip)" >> $GITHUB_OUTPUT
          echo "windows_ip=$(terraform output -raw windows_ip)" >> $GITHUB_OUTPUT
          echo "Linux instance created with IP: $(terraform output -raw linux_ip)"
          echo "Windows instance created with IP: $(terraform output -raw windows_ip)"

      - name: Upload SSH key for later jobs
        uses: actions/upload-artifact@v4
        with:
          name: linux_ssh_key
          path: terraform/ec2_user_rsa

    outputs:
      linux_ip: ${{ steps.tf_outputs.outputs.linux_ip }}
      windows_ip: ${{ steps.tf_outputs.outputs.windows_ip }}

  wait_for_ready:
    needs: provision
    runs-on: ubuntu-latest
    steps:
      - name: Download SSH key
        uses: actions/download-artifact@v4
        with:
          name: linux_ssh_key

      - name: Debug instance and network status
        run: |
          echo "=== INSTANCE AND NETWORK DEBUG ==="
          echo "Linux IP: ${{ needs.provision.outputs.linux_ip }}"
          echo "Windows IP: ${{ needs.provision.outputs.windows_ip }}"
          
          # Check instance status
          echo "Checking Linux instance status..."
          aws ec2 describe-instances \
            --filters "Name=ip-address,Values=${{ needs.provision.outputs.linux_ip }}" \
            --query 'Reservations[].Instances[].{InstanceId:InstanceId,State:State.Name,PublicIP:PublicIpAddress,PrivateIP:PrivateIpAddress}' \
            --output table || echo "Failed to get instance info"
          
          # Check security groups
          echo "Checking security groups..."
          aws ec2 describe-instances \
            --filters "Name=ip-address,Values=${{ needs.provision.outputs.linux_ip }}" \
            --query 'Reservations[].Instances[].SecurityGroups[].{GroupId:GroupId,GroupName:GroupName}' \
            --output table || echo "Failed to get security group info"
          
          # Check route table
          echo "Checking route table..."
          aws ec2 describe-route-tables \
            --filters "Name=association.subnet-id,Values=*" \
            --query 'RouteTables[].Routes[?GatewayId!=`null`].{GatewayId:GatewayId,DestinationCidrBlock:DestinationCidrBlock}' \
            --output table || echo "Failed to get route table info"
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_DEFAULT_REGION: us-east-1

      - name: Wait for Linux SSH
        run: |
          chmod 600 ec2_user_rsa
          echo "=== SSH CONNECTIVITY DEBUG ==="
          echo "Target IP: ${{ needs.provision.outputs.linux_ip }}"
          echo "SSH key exists: $(ls -la ec2_user_rsa)"
          echo "SSH key permissions: $(ls -la ec2_user_rsa | awk '{print $1}')"
          
          # Wait for instance to be ready (longer timeout)
          echo "Waiting for instance to be ready..."
          for attempt in {1..30}; do
            echo "Attempt $attempt/30: Testing SSH connectivity..."
            
            # Test basic connectivity first
            if nc -z -w 5 ${{ needs.provision.outputs.linux_ip }} 22; then
              echo "Port 22 is reachable, testing SSH..."
              
              # Try to detect the correct username by trying common ones
              for username in ubuntu ec2-user admin; do
                echo "Trying username: $username"
                
                # Test SSH with timeout and verbose output
                if timeout 10 ssh -v -o StrictHostKeyChecking=no -o ConnectTimeout=5 -o BatchMode=yes -i ec2_user_rsa $username@${{ needs.provision.outputs.linux_ip }} "echo ready" 2>&1; then
                  echo "Linux SSH is ready with username: $username!"
                  echo "DETECTED_USERNAME=$username" >> $GITHUB_ENV
                  exit 0
                else
                  echo "Username $username failed, trying next..."
                fi
              done
            else
              echo "Port 22 not reachable yet..."
            fi
            
            echo "Waiting 10 seconds before next attempt..."
            sleep 10
          done
          
          echo "ERROR: Linux SSH not reachable after 5 minutes."
          echo "Final connectivity test:"
          nc -zv ${{ needs.provision.outputs.linux_ip }} 22 || echo "Port 22 still not reachable"
          exit 1

      - name: Set output for detected username
        id: set_username
        run: echo "detected_username=${DETECTED_USERNAME}" >> $GITHUB_OUTPUT

      - name: Wait for Windows RDP/SMB
        run: |
          echo "=== WINDOWS SMB CONNECTIVITY DEBUG ==="
          echo "Target IP: ${{ needs.provision.outputs.windows_ip }}"
          echo "Testing SMB connectivity on port 445..."
          
          # Wait longer for Windows to fully boot and configure SMB
          for i in {1..10}; do
            echo "Attempt $i/10: Testing SMB connectivity..."
            
            # Test basic connectivity first
            if nc -z -w 5 ${{ needs.provision.outputs.windows_ip }} 445; then
              echo "Windows SMB is ready on port 445!"
              exit 0
            else
              echo "Port 445 not reachable yet..."
              
              # Also test RDP port to see if Windows is responding at all
              if nc -z -w 5 ${{ needs.provision.outputs.windows_ip }} 3389; then
                echo "RDP port 3389 is reachable, Windows is booted but SMB not ready yet"
              else
                echo "Neither SMB (445) nor RDP (3389) ports are reachable"
              fi
            fi
            
            echo "Waiting 15 seconds before next attempt..."
            sleep 15
          done
          
          echo "ERROR: Windows SMB not reachable after 2.5 minutes."
          echo "Final connectivity test:"
          nc -zv ${{ needs.provision.outputs.windows_ip }} 445 || echo "Port 445 still not reachable"
          nc -zv ${{ needs.provision.outputs.windows_ip }} 3389 || echo "Port 3389 also not reachable"
          exit 1

    outputs:
      detected_username: ${{ steps.set_username.outputs.detected_username }}

  run_tests:
    needs: [provision, wait_for_ready]
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Download SSH key
        uses: actions/download-artifact@v4
        with:
          name: linux_ssh_key

      - name: Run tests
        working-directory: ${{ github.workspace }}
        env:
          # Linux host IP comes from Terraform outputs, not secrets
          TEST_LINUX_HOST: ${{ needs.provision.outputs.linux_ip }}
          TEST_LINUX_USER: ${{ needs.wait_for_ready.outputs.detected_username }}
          TEST_LINUX_SSH_KEY: ${{ github.workspace }}/ec2_user_rsa
          # Windows credentials still need secrets
          TEST_WINDOWS_HOST: ${{ needs.provision.outputs.windows_ip }}
          TEST_WINDOWS_USER: Administrator
          TEST_WINDOWS_PASS: ${{ secrets.TEST_WINDOWS_PASS }}
        run: |
          # Debug information before installation
          echo "=== PRE-INSTALLATION DEBUG ==="
          echo "Python version: $(python --version)"
          echo "Pip version: $(pip --version)"
          echo "Current directory: $(pwd)"
          echo "Files in current directory: $(ls -la)"
          echo "Files in core directory: $(ls -la core/)"
          echo "SSH key exists: $(ls -la ec2_user_rsa)"
          
          # Install dependencies first
          echo "=== INSTALLING DEPENDENCIES ==="
          pip install --upgrade pip
          pip install -r requirements.txt
          
          # Install the package in development mode
          echo "=== INSTALLING PACKAGE ==="
          pip install -e .
          
          echo "=== POST-INSTALLATION DEBUG ==="
          echo "Python path: $(python -c 'import sys; print("\\n".join(sys.path))')"
          
          # Test imports
          echo "=== TESTING IMPORTS ==="
          python -c "import sys; print('Python executable:', sys.executable)"
          python -c "import core; print('Core module imported successfully')" || echo "Core import failed"
          python -c "from core.connection_manager import connect_with_fallback; print('connection_manager imported successfully')" || echo "connection_manager import failed"
          
          # List installed packages
          echo "=== INSTALLED PACKAGES ==="
          pip list | grep -E "(hai|core|pydantic)" || echo "No relevant packages found"
          
          # Run tests with verbose output
          echo "=== RUNNING TESTS ==="
          python -m pytest tests/test_integration_real_servers.py -v --tb=short

      - name: Upload test logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-logs
          path: logs/

  cleanup:
    needs: [provision, run_tests]
    runs-on: ubuntu-latest
    if: always()
    steps:
      - uses: actions/checkout@v4

      - name: Setup AWS CLI
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-1

      - name: Targeted cleanup - Remove workflow-specific key pairs
        run: |
          echo "=== TARGETED CLEANUP - KEY PAIRS ==="
          echo "Removing only workflow-specific key pairs..."
          
          # Only delete our specific key pair (Windows uses password authentication)
          aws ec2 delete-key-pair --key-name hai-ci-ec2-user-key 2>/dev/null || echo "Failed to delete hai-ci-ec2-user-key, continuing..."
          
          echo "Key pair cleanup completed"
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_DEFAULT_REGION: us-east-1

      - name: Targeted cleanup - Delete workflow-specific EC2 instances
        run: |
          echo "=== TARGETED CLEANUP - EC2 INSTANCES ==="
          echo "Checking for workflow-specific EC2 instances..."
          
          # Get list of instances tagged with our workflow identifier
          instance_list=$(aws ec2 describe-instances \
            --filters "Name=tag:ManagedBy,Values=hai-ci-workflow" \
            --query 'Reservations[].Instances[].InstanceId' \
            --output text 2>/dev/null || echo "")
          
          if [ -n "$instance_list" ]; then
            echo "Found workflow-specific instances to terminate: $instance_list"
            for instance_id in $instance_list; do
              echo "Terminating workflow instance $instance_id"
              aws ec2 terminate-instances --instance-ids $instance_id 2>/dev/null || echo "Failed to terminate instance $instance_id, continuing..."
            done
            
            # Wait for instances to be terminated
            echo "Waiting for instances to terminate..."
            for instance_id in $instance_list; do
              echo "Waiting for instance $instance_id to terminate..."
              aws ec2 wait instance-terminated --instance-ids $instance_id 2>/dev/null || echo "Instance $instance_id termination wait failed, continuing..."
            done
          else
            echo "No workflow-specific instances found"
          fi
          
          echo "EC2 instance cleanup completed"
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_DEFAULT_REGION: us-east-1

      - name: Targeted cleanup - Delete workflow-specific security groups
        run: |
          echo "=== TARGETED CLEANUP - SECURITY GROUPS ==="
          echo "Checking for workflow-specific security groups..."
          
          # Get list of security groups tagged with our workflow identifier
          sg_list=$(aws ec2 describe-security-groups \
            --filters "Name=tag:ManagedBy,Values=hai-ci-workflow" \
            --query 'SecurityGroups[].GroupId' \
            --output text 2>/dev/null || echo "")
          
          if [ -n "$sg_list" ]; then
            echo "Found workflow-specific security groups to delete: $sg_list"
            for sg_id in $sg_list; do
              echo "Deleting workflow security group $sg_id"
              aws ec2 delete-security-group --group-id $sg_id 2>/dev/null || echo "Failed to delete security group $sg_id, continuing..."
            done
          else
            echo "No workflow-specific security groups found"
          fi
          
          echo "Security group cleanup completed"
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_DEFAULT_REGION: us-east-1

      - name: Targeted cleanup - Delete workflow-specific subnets
        run: |
          echo "=== TARGETED CLEANUP - SUBNETS ==="
          echo "Checking for workflow-specific subnets..."
          
          # Get list of subnets tagged with our workflow identifier
          subnet_list=$(aws ec2 describe-subnets \
            --filters "Name=tag:ManagedBy,Values=hai-ci-workflow" \
            --query 'Subnets[].SubnetId' \
            --output text 2>/dev/null || echo "")
          
          if [ -n "$subnet_list" ]; then
            echo "Found workflow-specific subnets to delete: $subnet_list"
            for subnet_id in $subnet_list; do
              echo "Deleting workflow subnet $subnet_id"
              aws ec2 delete-subnet --subnet-id $subnet_id 2>/dev/null || echo "Failed to delete subnet $subnet_id, continuing..."
            done
          else
            echo "No workflow-specific subnets found"
          fi
          
          echo "Subnet cleanup completed"
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_DEFAULT_REGION: us-east-1

      - name: Targeted cleanup - Delete workflow-specific route tables
        run: |
          echo "=== TARGETED CLEANUP - ROUTE TABLES ==="
          echo "Checking for workflow-specific route tables..."
          
          # Get list of route tables tagged with our workflow identifier
          rt_list=$(aws ec2 describe-route-tables \
            --filters "Name=tag:ManagedBy,Values=hai-ci-workflow" \
            --query 'RouteTables[].RouteTableId' \
            --output text 2>/dev/null || echo "")
          
          if [ -n "$rt_list" ]; then
            echo "Found workflow-specific route tables to delete: $rt_list"
            for rt_id in $rt_list; do
              echo "Deleting workflow route table $rt_id"
              aws ec2 delete-route-table --route-table-id $rt_id 2>/dev/null || echo "Failed to delete route table $rt_id, continuing..."
            done
          else
            echo "No workflow-specific route tables found"
          fi
          
          echo "Route table cleanup completed"
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_DEFAULT_REGION: us-east-1

      - name: Targeted cleanup - Delete workflow-specific internet gateways
        run: |
          echo "=== TARGETED CLEANUP - INTERNET GATEWAYS ==="
          echo "Checking for workflow-specific internet gateways..."
          
          # Get list of internet gateways tagged with our workflow identifier
          igw_list=$(aws ec2 describe-internet-gateways \
            --filters "Name=tag:ManagedBy,Values=hai-ci-workflow" \
            --query 'InternetGateways[].InternetGatewayId' \
            --output text 2>/dev/null || echo "")
          
          if [ -n "$igw_list" ]; then
            echo "Found workflow-specific internet gateways to delete: $igw_list"
            for igw_id in $igw_list; do
              echo "Processing workflow IGW $igw_id"
              
              # Get VPC ID for this IGW
              vpc_id=$(aws ec2 describe-internet-gateways \
                --internet-gateway-ids $igw_id \
                --query 'InternetGateways[0].Attachments[0].VpcId' \
                --output text 2>/dev/null || echo "")
              
              if [ -n "$vpc_id" ]; then
                echo "Detaching IGW $igw_id from VPC $vpc_id"
                aws ec2 detach-internet-gateway --internet-gateway-id $igw_id --vpc-id $vpc_id 2>/dev/null || echo "Failed to detach IGW $igw_id, continuing..."
              fi
              
              echo "Deleting workflow IGW $igw_id"
              aws ec2 delete-internet-gateway --internet-gateway-id $igw_id 2>/dev/null || echo "Failed to delete IGW $igw_id, continuing..."
            done
          else
            echo "No workflow-specific internet gateways found"
          fi
          
          echo "Internet gateway cleanup completed"
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_DEFAULT_REGION: us-east-1

      - name: Targeted cleanup - Delete workflow-specific VPCs
        run: |
          echo "=== TARGETED CLEANUP - VPCS ==="
          echo "Cleaning up only workflow-specific VPCs..."
          
          # Get list of VPCs tagged with our workflow identifier
          vpc_list=$(aws ec2 describe-vpcs \
            --filters "Name=tag:ManagedBy,Values=hai-ci-workflow" \
            --query 'Vpcs[].VpcId' \
            --output text 2>/dev/null || echo "")
          
          if [ -n "$vpc_list" ]; then
            echo "Found workflow-specific VPCs to delete: $vpc_list"
            for vpc_id in $vpc_list; do
              echo "Deleting workflow VPC $vpc_id"
              aws ec2 delete-vpc --vpc-id $vpc_id 2>/dev/null || echo "Failed to delete VPC $vpc_id, continuing..."
            done
          else
            echo "No workflow-specific VPCs found"
          fi
          
          echo "VPC cleanup completed"
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_DEFAULT_REGION: us-east-1

      - name: Cleanup summary
        run: |
          echo "=== TARGETED CLEANUP SUMMARY ==="
          echo "All targeted cleanup operations completed!"
          echo "Only resources tagged with 'ManagedBy=hai-ci-workflow' were cleaned up."
          echo "Existing resources not created by this workflow were preserved."
          echo ""
          echo "Resources cleaned up:"
          echo "- EC2 instances with ManagedBy=hai-ci-workflow tag"
          echo "- Security groups with ManagedBy=hai-ci-workflow tag"
          echo "- Subnets with ManagedBy=hai-ci-workflow tag"
          echo "- Route tables with ManagedBy=hai-ci-workflow tag"
          echo "- Internet gateways with ManagedBy=hai-ci-workflow tag"
          echo "- VPCs with ManagedBy=hai-ci-workflow tag"
          echo "- Key pairs: hai-ci-ec2-user-key"
