name: Provision Infra and Run Tests

on:
  push:
    branches: [main]

jobs:
  provision:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Ensure SSH key exists for Terraform
        run: |
          if [ ! -f terraform/id_rsa.pub ]; then
            ssh-keygen -t rsa -b 2048 -f terraform/id_rsa -N ""
          fi

      - name: Generate new SSH key for ec2-user
        run: |
          # Generate a new SSH key pair specifically for ec2-user
          ssh-keygen -t rsa -b 2048 -f terraform/ec2_user_rsa -N ""
          echo "Generated new SSH key pair for ec2-user"
          echo "Public key:"
          cat terraform/ec2_user_rsa.pub

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: "1.5.0"

      - name: Verify Terraform Installation
        run: |
          echo "=== TERRAFORM INSTALLATION VERIFICATION ==="
          echo "Terraform version:"
          terraform version
          echo "Terraform location:"
          which terraform
          echo "PATH:"
          echo $PATH
          echo "=== END VERIFICATION ==="

      - name: Validate AWS Credentials
        run: |
          echo "Validating AWS credentials..."
          aws sts get-caller-identity
          echo "AWS credentials are valid!"
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_DEFAULT_REGION: us-east-1

      - name: Remove existing AWS key pair if present
        run: |
          aws ec2 delete-key-pair --key-name hai-ci-key || true
          aws ec2 delete-key-pair --key-name hai-ci-ec2-user-key || true
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_DEFAULT_REGION: us-east-1

      - name: Clean up conflicting subnets
        run: |
          echo "Checking for existing subnets that might conflict..."
          # Get VPC ID
          VPC_ID=$(aws ec2 describe-vpcs --query 'Vpcs[0].VpcId' --output text 2>/dev/null || echo "")
          if [ ! -z "$VPC_ID" ]; then
            echo "Found VPC: $VPC_ID"
            # List subnets in the VPC that might conflict with our new CIDR
            SUBNETS=$(aws ec2 describe-subnets --filters "Name=vpc-id,Values=$VPC_ID" --query 'Subnets[?CidrBlock==`10.0.200.0/24`].SubnetId' --output text 2>/dev/null || echo "")
            if [ ! -z "$SUBNETS" ]; then
              echo "Found conflicting subnet(s): $SUBNETS"
              echo "Deleting conflicting subnets..."
              for SUBNET in $SUBNETS; do
                aws ec2 delete-subnet --subnet-id $SUBNET || echo "Failed to delete subnet $SUBNET"
              done
            else
              echo "No conflicting subnets found with CIDR 10.0.200.0/24"
            fi
            
            # Also check for any subnets in the 10.0.x.x range that might overlap
            echo "Checking for any subnets in 10.0.x.x range..."
            ALL_SUBNETS=$(aws ec2 describe-subnets --filters "Name=vpc-id,Values=$VPC_ID" --query 'Subnets[?starts_with(CidrBlock, `10.0.`)].{SubnetId:SubnetId,CidrBlock:CidrBlock}' --output json 2>/dev/null || echo "[]")
            echo "Existing subnets in 10.0.x.x range: $ALL_SUBNETS"
            
            # If there are any subnets in the 10.0.x.x range, delete them all to avoid conflicts
            SUBNET_IDS=$(aws ec2 describe-subnets --filters "Name=vpc-id,Values=$VPC_ID" --query 'Subnets[?starts_with(CidrBlock, `10.0.`)].SubnetId' --output text 2>/dev/null || echo "")
            if [ ! -z "$SUBNET_IDS" ]; then
              echo "Found existing subnets in 10.0.x.x range, deleting all to avoid conflicts: $SUBNET_IDS"
              for SUBNET_ID in $SUBNET_IDS; do
                echo "Deleting subnet: $SUBNET_ID"
                aws ec2 delete-subnet --subnet-id $SUBNET_ID || echo "Failed to delete subnet $SUBNET_ID"
              done
            fi
          else
            echo "No VPC found"
          fi
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_DEFAULT_REGION: us-east-1

      - name: Terraform Init and Apply
        run: |
          echo "=== TERRAFORM EXECUTION DEBUG ==="
          echo "Current directory: $(pwd)"
          echo "Terraform directory contents:"
          ls -la terraform/
          echo "Terraform executable:"
          which terraform
          echo "Terraform version:"
          terraform version
          echo "=== STARTING TERRAFORM ==="
          cd terraform
          echo "Changed to terraform directory: $(pwd)"
          terraform init
          terraform apply -auto-approve -var="windows_password=${{ secrets.TEST_WINDOWS_PASS }}"
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}

      - name: Output VM IPs
        id: tf_outputs
        run: |
          echo "=== TERRAFORM OUTPUT DEBUG ==="
          echo "Current directory: $(pwd)"
          echo "Terraform executable:"
          which terraform
          echo "Terraform version:"
          terraform version
          echo "=== GETTING TERRAFORM OUTPUTS ==="
          cd terraform
          echo "Changed to terraform directory: $(pwd)"
          echo "linux_ip=$(terraform output -raw linux_ip)" >> $GITHUB_OUTPUT
          echo "windows_ip=$(terraform output -raw windows_ip)" >> $GITHUB_OUTPUT
          echo "Linux instance created with IP: $(terraform output -raw linux_ip)"
          echo "Windows instance created with IP: $(terraform output -raw windows_ip)"

      - name: Upload SSH key for later jobs
        uses: actions/upload-artifact@v4
        with:
          name: linux_ssh_key
          path: terraform/ec2_user_rsa

    outputs:
      linux_ip: ${{ steps.tf_outputs.outputs.linux_ip }}
      windows_ip: ${{ steps.tf_outputs.outputs.windows_ip }}

  wait_for_ready:
    needs: provision
    runs-on: ubuntu-latest
    steps:
      - name: Download SSH key
        uses: actions/download-artifact@v4
        with:
          name: linux_ssh_key

      - name: Wait for Linux SSH
        run: |
          chmod 600 ec2_user_rsa
          # Try to detect the correct username by trying common ones
          for username in ec2-user ubuntu admin; do
            echo "Trying username: $username"
            if ssh -o StrictHostKeyChecking=no -i ec2_user_rsa $username@${{ needs.provision.outputs.linux_ip }} "echo ready" 2>/dev/null; then
              echo "Linux SSH is ready with username: $username!"
              echo "DETECTED_USERNAME=$username" >> $GITHUB_ENV
              exit 0
            fi
            echo "Username $username failed, trying next..."
          done
          echo "ERROR: Linux SSH not reachable with any username after 30 seconds."; exit 1

      - name: Output Detected Username
        run: |
          echo "Detected Linux username: ${{ env.DETECTED_USERNAME }}"

      - name: Set output for detected username
        id: set_username
        run: echo "detected_username=${DETECTED_USERNAME}" >> $GITHUB_OUTPUT

      - name: Wait for Windows RDP/SMB
        run: |
          for i in {1..3}; do
            if nc -z -v ${{ needs.provision.outputs.windows_ip }} 445; then
              echo "Windows SMB is ready!"; exit 0;
            fi
            echo "Waiting for SMB..."; sleep 10;
          done
          echo "ERROR: Windows SMB not reachable after 30 seconds."; exit 1

    outputs:
      detected_username: ${{ steps.set_username.outputs.detected_username }}

  run_tests:
    needs: [wait_for_ready, provision]
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Download SSH key
        uses: actions/download-artifact@v4
        with:
          name: linux_ssh_key

      - name: Set SSH key permissions
        run: |
          chmod 600 ec2_user_rsa
          echo "SSH key permissions set"

      - name: Test SSH to Linux
        working-directory: ${{ github.workspace }}
        run: bash tests/test_linux_ssh_connectivity.sh ${{ needs.provision.outputs.linux_ip }} ${{ needs.wait_for_ready.outputs.detected_username }}
        env:
          PYTHONPATH: ${{ github.workspace }}

      - name: Test SMB to Windows
        shell: pwsh
        working-directory: ${{ github.workspace }}
        run: tests/test_windows_smb_connectivity.ps1 -TargetIP ${{ needs.provision.outputs.windows_ip }}
        env:
          PYTHONPATH: ${{ github.workspace }}

      - name: Run tests
        working-directory: ${{ github.workspace }}
        env:
          # Linux host IP comes from Terraform outputs, not secrets
          TEST_LINUX_HOST: ${{ needs.provision.outputs.linux_ip }}
          TEST_LINUX_USER: ${{ needs.wait_for_ready.outputs.detected_username }}
          TEST_LINUX_SSH_KEY: ${{ github.workspace }}/ec2_user_rsa
          # Windows credentials still need secrets
          TEST_WINDOWS_HOST: ${{ needs.provision.outputs.windows_ip }}
          TEST_WINDOWS_USER: Administrator
          TEST_WINDOWS_PASS: ${{ secrets.TEST_WINDOWS_PASS }}
        run: |
          # Debug information before installation
          echo "=== PRE-INSTALLATION DEBUG ==="
          echo "PYTHONPATH=$PYTHONPATH"
          echo "Current directory: $(pwd)"
          echo "Files in current directory: $(ls -la)"
          echo "Files in core directory: $(ls -la core/)"
          echo "SSH key exists: $(ls -la ec2_user_rsa)"
          echo "Python path: $(python -c 'import sys; print("\\n".join(sys.path))')"
          
          # Install dependencies first
          echo "=== INSTALLING DEPENDENCIES ==="
          pip install paramiko>=2.7.0 impacket>=0.9.0 pytest>=6.0.0 pyyaml>=5.0 cryptography>=3.0 bcrypt>=3.0 pynacl>=1.0
          
          # Try multiple installation methods
          echo "=== INSTALLING PACKAGE ==="
          
          # Method 1: Install in development mode
          pip install -e . || echo "pip install -e . failed"
          
          # Method 2: Add current directory to PYTHONPATH
          export PYTHONPATH="${GITHUB_WORKSPACE}:${PYTHONPATH:-}"
          
          # Method 3: Try installing with pip install .
          pip install . || echo "pip install . failed"
          
          echo "=== POST-INSTALLATION DEBUG ==="
          echo "PYTHONPATH=$PYTHONPATH"
          echo "Python path: $(python -c 'import sys; print("\\n".join(sys.path))')"
          
          # Test imports
          echo "=== TESTING IMPORTS ==="
          python -c "import sys; print('Python executable:', sys.executable)"
          python -c "import core; print('Core module imported successfully')" || echo "Core import failed"
          python -c "from core.connection_manager import connect_with_fallback; print('connection_manager imported successfully')" || echo "connection_manager import failed"
          
          # List installed packages
          echo "=== INSTALLED PACKAGES ==="
          pip list | grep -E "(hai|core)" || echo "No hai or core packages found"
          
          # Run tests with verbose output
          echo "=== RUNNING TESTS ==="
          python -m pytest tests/test_integration_real_servers.py -v --tb=short

      - name: Upload test logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-logs
          path: logs/

  cleanup:
    needs: [provision, run_tests]
    runs-on: ubuntu-latest
    if: always()
    steps:
      - uses: actions/checkout@v4

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3

      - name: Destroy Terraform-managed infrastructure
        run: |
          cd terraform
          terraform init
          terraform destroy -auto-approve
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_DEFAULT_REGION: us-east-1

      - name: Remove leftover key pairs
        run: |
          aws ec2 delete-key-pair --key-name hai-ci-key || true
          aws ec2 delete-key-pair --key-name hai-ci-ec2-user-key || true
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_DEFAULT_REGION: us-east-1

      - name: Delete unattached network interfaces (ENIs)
        run: |
          echo "Checking for unattached ENIs..."
          for eni_id in $(aws ec2 describe-network-interfaces \
            --filters Name=status,Values=available \
            --query 'NetworkInterfaces[].NetworkInterfaceId' \
            --output text); do
            echo "Deleting ENI $eni_id"
            aws ec2 delete-network-interface --network-interface-id $eni_id || true
          done
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_DEFAULT_REGION: us-east-1

      - name: Delete leftover VPCs (dangerous!)
        run: |
          echo "Cleaning up non-default VPCs..."
          for vpc_id in $(aws ec2 describe-vpcs --query 'Vpcs[?IsDefault==`false`].VpcId' --output text); do
            echo "Deleting VPC $vpc_id"
            # Detach and delete internet gateways
            for igw_id in $(aws ec2 describe-internet-gateways --filters Name=attachment.vpc-id,Values=$vpc_id --query 'InternetGateways[].InternetGatewayId' --output text); do
              aws ec2 detach-internet-gateway --internet-gateway-id $igw_id --vpc-id $vpc_id || true
              aws ec2 delete-internet-gateway --internet-gateway-id $igw_id || true
            done
            # Delete subnets
            for subnet_id in $(aws ec2 describe-subnets --filters Name=vpc-id,Values=$vpc_id --query 'Subnets[].SubnetId' --output text); do
              aws ec2 delete-subnet --subnet-id $subnet_id || true
            done
            # Delete route tables (skip the main one)
            for rt_id in $(aws ec2 describe-route-tables --filters Name=vpc-id,Values=$vpc_id --query 'RouteTables[?Associations[?Main==`false`]].RouteTableId' --output text); do
              aws ec2 delete-route-table --route-table-id $rt_id || true
            done
            # Delete security groups (skip default)
            for sg_id in $(aws ec2 describe-security-groups --filters Name=vpc-id,Values=$vpc_id --query 'SecurityGroups[?GroupName!=`default`].GroupId' --output text); do
              aws ec2 delete-security-group --group-id $sg_id || true
            done
            # Finally delete the VPC
            aws ec2 delete-vpc --vpc-id $vpc_id || true
          done
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_DEFAULT_REGION: us-east-1
